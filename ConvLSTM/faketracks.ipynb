{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab6abe4-4467-41c1-bce1-eb79f84ee265",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This takes the output from the ConvLSTM model, adds a randomly assigned \"track\" to the data, and then recursively calculates the outout until there is a string of 30 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebd2632-1b40-4814-8c17-38c972fcbfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are the versions used in Scott's paper\n",
    "!pip3 install keras==2.6\n",
    "!pip3 install TensorFlow==2.6.1\n",
    "!pip3 install TensorFlow-Addons==0.14.0\n",
    "!pip3 install numpy==1.21.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae940cb-0a26-4bd9-b3d9-113652b0d6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This randomly picks a track and adds it to the output\n",
    "import numpy as np\n",
    "def faketrack(datadir,output,n_train=2000,batch_size=25,n_t=30):\n",
    "    tracks=[]\n",
    "    for sample in range(output.shape[0]):\n",
    "        batchno=np.random.randint(n_train)\n",
    "        sampleno=np.random.randint(batch_size)\n",
    "        day=np.random.randint(n_t)\n",
    "        track=np.load(datadir+f'training/batch{batchno}_invar.npy')\n",
    "        track=track[sampleno,day,:,:,0]!=0\n",
    "        tracks.append(track)\n",
    "    tracks=np.stack(tracks)\n",
    "    return np.expand_dims(np.squeeze(output)*tracks,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d318989-b450-412b-8ec6-391389f4e1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.generators import *\n",
    "from src.models import *\n",
    "from src.losses import *\n",
    "n_t=30\n",
    "n_train=1000\n",
    "experiment_name = 'convlstm_sla_future_'+ f'{n_t}days_{n_train}samples'\n",
    "mean_ssh=np.load(\"gs_mean_ssh_future.npy\")\n",
    "std_ssh=np.load(\"gs_std_ssh_future.npy\")\n",
    "mean_sst=np.load(\"gs_mean_sst_future.npy\")\n",
    "std_sst=np.load(\"gs_std_sst_future.npy\")\n",
    "stats = (mean_ssh, std_ssh, mean_sst, std_sst)\n",
    "datadir='/home/jovyan/pre-processed-future-fixed/'\n",
    "model_weights_dir = '/home/jovyan/deep-learning-ssh-mapping-JAMES-paper/src/model_weights_future/'+experiment_name+'.h5'\n",
    "#load the model and the weights from training\n",
    "\n",
    "model=create_ConvLSTM_SLA(n_t,one_output=True)\n",
    "model.load_weights(model_weights_dir)\n",
    "val='validation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c131b4e-3d87-4c5a-a19e-2c6ea8829307",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This repeatedly runs the model on the data\n",
    "n_val=10\n",
    "invar=[]\n",
    "\n",
    "for ID in range(n_val):\n",
    "    filename=datadir+val+f'batch{ID}_invar.npy'\n",
    "    invar.append(np.load(filename)[:,:,:,:,0])\n",
    "invar=np.concatenate(invar,axis=0)\n",
    "prediction=[]\n",
    "for day in range(n_t):\n",
    "    prediction.append(model.predict(invar))\n",
    "    invar=np.concatenate([invar[:,1:,:],faketrack(datadir,prediction[-1],n_train=1000)],axis=1) #8/15 this rolls the input period to include the prediction\n",
    "prediction=np.stack(prediction,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7963fc36-978d-4e8a-b665-81ff4960eaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This loads the output data\n",
    "batch_size=25\n",
    "outvar=np.zeros((n_val,batch_size,n_t,10000,3))\n",
    "\n",
    "for ID in range(n_val):\n",
    "    filename=datadir+f'validation/batch{ID}_outvar.npy'\n",
    "    out=np.load(filename)\n",
    "    l=out.shape[2]\n",
    "    outvar[ID,:,:,:l,:]=out\n",
    "    \n",
    "outvar=outvar.reshape((n_val*batch_size,n_t,10000,3))\n",
    "track_array = np.zeros(outvar.shape)\n",
    "for batch in range(outvar.shape[0]):\n",
    "    for t in range(outvar.shape[1]):\n",
    "        x = outvar[batch,t,:,0].copy()\n",
    "        x[x!=0] = ((x[x!=0]+0.5*960e3)/960e3)*(128-1)\n",
    "        y = outvar[batch,t,:,1].copy()\n",
    "        y[y!=0] = ((-y[y!=0]+0.5*960e3)/960e3)*(128-1)\n",
    "        outvar[batch,t,:,0]=x\n",
    "        outvar[batch,t,:,1]=y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdfc6af-6685-49ec-84dd-e2f053695342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilinear_interp(x,y,x_grid,y_grid,z_grid):\n",
    "    dx = x_grid[1]-x_grid[0]\n",
    "    dy = y_grid[1]-y_grid[0]\n",
    "    Nx = x_grid.shape[0]-1\n",
    "    Ny = y_grid.shape[0]-1\n",
    "    # print(Ny)\n",
    "    # print(x_grid.shape)\n",
    "\n",
    "\n",
    "    x0_idx = (((x-x_grid[0])/np.abs(x_grid[-1]-x_grid[0]))*Nx).astype('int')\n",
    "    y0_idx = (((y-y_grid[0])/np.abs(y_grid[-1]-y_grid[0]))*Ny).astype('int')\n",
    "    # print(y0_idx)\n",
    "\n",
    "    x1_idx = x0_idx + 1\n",
    "    y1_idx = y0_idx + 1\n",
    "\n",
    "    x0 = x_grid[x0_idx]\n",
    "    x1 = x_grid[x1_idx]\n",
    "    y0 = y_grid[y0_idx]\n",
    "    y1 = y_grid[y1_idx]\n",
    "\n",
    "    x_n = (x-x0)/dx\n",
    "    y_n = (y-y0)/dy\n",
    "\n",
    "    z00 = z_grid[Ny-y0_idx,x0_idx]\n",
    "    z10 = z_grid[Ny-y0_idx,x1_idx]\n",
    "    z01 = z_grid[Ny-y1_idx,x0_idx]\n",
    "    z11 = z_grid[Ny-y1_idx,x1_idx]\n",
    "\n",
    "    z_interp = z00*(1-x_n)*(1-y_n)+z10*x_n*(1-y_n)+z01*y_n*(1-x_n)+z11*x_n*y_n\n",
    "    return z_interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86290a3d-75ba-4cf8-a986-c1305a23efe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This calculates the MSE loss\n",
    "per_pred = np.squeeze(prediction)*std_ssh+mean_ssh\n",
    "\n",
    "tracks_persistence = outvar\n",
    "x_grid = np.arange(128)\n",
    "y_grid = np.arange(128)\n",
    "loss = np.zeros(outvar.shape[:2])\n",
    "for t in range(outvar.shape[0]):\n",
    "    for l_t in range(outvar.shape[1]):\n",
    "        ssh_true = tracks_persistence[t,l_t,:,-1]\n",
    "        x = tracks_persistence[t,l_t,:,0]\n",
    "        y = tracks_persistence[t,l_t,:,1]\n",
    "        x = x[ssh_true!=0] #there were some SSH = NaN observations that I zero padded in the pre-processing\n",
    "        y = 127-y[ssh_true!=0]\n",
    "        ssh_true = ssh_true[ssh_true!=0]\n",
    "        ssh_pred = bilinear_interp(x,y,x_grid,y_grid,per_pred[t,l_t,:,:])\n",
    "        loss[t,l_t] = np.mean((ssh_true-ssh_pred)**2)\n",
    "loss[loss==0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a028c2-754c-4614-bfe4-1b1e191c2394",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "import matplotlib.pyplot as plt\n",
    "dailyloss=np.nanmean(loss,axis=0)**0.5\n",
    "plt.plot(dailyloss)\n",
    "plt.xlabel(\"Lead time\")\n",
    "plt.ylabel(\"RMSE loss\")\n",
    "plt.title(\"Recursively calculated loss\")\n",
    "n_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d1883a-b09e-4dc2-b9a6-7888f47c5219",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This creates images of the results which can then be turned into a video using ffmpeg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import scipy\n",
    "\n",
    "\n",
    "batchno=6 #which batch we will inspect\n",
    "sampleno=0 #which sample we will inspect\n",
    "tmax=30 #days per sample\n",
    "n=128 #pixels per region\n",
    "L_x = 960e3 # size of domain\n",
    "L_y = 960e3  # size of domain\n",
    "\n",
    "\n",
    "savedir='/home/jovyan/images/oneoutput/' #where you want to save the images to\n",
    "    \n",
    "index=0\n",
    "mode2='Validation'\n",
    "for batchno in range(1):\n",
    "    output_data=np.load(datadir+val+\"batch\"+str(batchno)+\"_outvar.npy\") #output data from batch to compare to\n",
    "    outputsample=output_data[sampleno,:,:,:] #specific sample\n",
    "    for day in range(tmax):\n",
    "\n",
    "        #make the axes and the colorbar\n",
    "        fig, axs = plt.subplot_mosaic([['ax1', 'ax1','ax2','ax2'],\n",
    "         ['ax1', 'ax1','ax2','ax2'],['colorbar', 'colorbar','colorbar','colorbar'],['BLANK', 'BLANK', 'BLANK','BLANK'],],empty_sentinel=\"BLANK\",figsize=(10,10))\n",
    "        cmap = mpl.cm.viridis\n",
    "        norm = mpl.colors.Normalize(vmin=-1, vmax=1)\n",
    "        fig.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=cmap),\n",
    "            cax=axs['colorbar'], orientation='horizontal', label='SSH')\n",
    "\n",
    "        #plot the prediction\n",
    "        axs['ax1'].imshow(prediction[batchno*25+sampleno,day,:,:]*std_ssh+mean_ssh,norm=norm,cmap=cmap)\n",
    "        input_=np.load(datadir+val+\"batch\"+str(batchno)+\"_invar.npy\")\n",
    "\n",
    "        #bin and plot the output data\n",
    "        outputgrid, _,_,_ = scipy.stats.binned_statistic_2d(outputsample[day,:,0].flatten(), outputsample[day,:,1].flatten(), outputsample[day,:,2].flatten(), statistic = 'mean', bins=n, range = [[-L_x/2, L_x/2],[-L_y/2, L_y/2]])\n",
    "        outputgrid = np.rot90(outputgrid)\n",
    "        outputgrid[np.isnan(outputgrid)] = 0\n",
    "        axs['ax2'].imshow(outputgrid,norm=norm,cmap=cmap)\n",
    "\n",
    "        #figure and axis titles\n",
    "        fig.suptitle(\"Mode:\"+ mode2 + \", Batch number: \" + str(batchno) + \", Sample number: \" + str(sampleno) + \", Day:\" + str(day), fontsize=16)\n",
    "        axs['ax1'].set_title(\"Model prediction\")\n",
    "        axs['ax2'].set_title(\"Binned output data\")\n",
    "\n",
    "        #save the figure to the output data\n",
    "        plt.savefig(savedir+(str(index).zfill(3))+'.jpg')\n",
    "        index+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
